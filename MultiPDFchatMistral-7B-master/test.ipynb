{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_session_state():\n",
    "    if 'history' not in st.session_state:\n",
    "        st.session_state['history'] = []\n",
    "\n",
    "    if 'generated' not in st.session_state:\n",
    "        st.session_state['generated'] = [\"Hello! Ask me anything about ðŸ¤—\"]\n",
    "\n",
    "    if 'past' not in st.session_state:\n",
    "        st.session_state['past'] = [\"Hey! ðŸ‘‹\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_chat(query, chain, history):\n",
    "    result = chain({\"question\": query, \"chat_history\": history})\n",
    "    history.append((query, result[\"answer\"]))\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chat_history(chain):\n",
    "    reply_container = st.container()\n",
    "    container = st.container()\n",
    "\n",
    "    with container:\n",
    "        with st.form(key='my_form', clear_on_submit=True):\n",
    "            user_input = st.text_input(\"Question:\", placeholder=\"Ask about your PDF\", key='input')\n",
    "            submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "        if submit_button and user_input:\n",
    "            with st.spinner('Generating response...'):\n",
    "                output = conversation_chat(user_input, chain, st.session_state['history'])\n",
    "\n",
    "            st.session_state['past'].append(user_input)\n",
    "            st.session_state['generated'].append(output)\n",
    "\n",
    "    if st.session_state['generated']:\n",
    "        with reply_container:\n",
    "            for i in range(len(st.session_state['generated'])):\n",
    "                message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"thumbs\")\n",
    "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"fun-emoji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversational_chain(vector_store):\n",
    "    # Create llm\n",
    "    llm = LlamaCpp(\n",
    "    streaming = True,\n",
    "    model_path=\"/Users/matansharon/python/chat_with_docs/MultiPDFchatMistral-7B-master/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    temperature=0.75,\n",
    "    top_p=1, \n",
    "    verbose=True,\n",
    "    n_ctx=4096\n",
    ")\n",
    "    \n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm=llm, chain_type='stuff',\n",
    "                                                 retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
    "                                                 memory=memory)\n",
    "    return chain\n",
    "\n",
    "chain=create_conversational_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Initialize session state\n",
    "    initialize_session_state()\n",
    "    st.title(\"Multi-PDF ChatBot using Mistral-7B-Instruct :books:\")\n",
    "    # Initialize Streamlit\n",
    "    st.sidebar.title(\"Document Processing\")\n",
    "    uploaded_files = st.sidebar.file_uploader(\"Upload files\", accept_multiple_files=True)\n",
    "\n",
    "\n",
    "    if uploaded_files:\n",
    "        text = []\n",
    "        for file in uploaded_files:\n",
    "            file_extension = os.path.splitext(file.name)[1]\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "                temp_file.write(file.read())\n",
    "                temp_file_path = temp_file.name\n",
    "\n",
    "            loader = None\n",
    "            if file_extension == \".pdf\":\n",
    "                loader = PyPDFLoader(temp_file_path)\n",
    "\n",
    "            if loader:\n",
    "                text.extend(loader.load())\n",
    "                os.remove(temp_file_path)\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
    "        text_chunks = text_splitter.split_documents(text)\n",
    "\n",
    "        # Create embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "                                           model_kwargs={'device': 'cpu'})\n",
    "\n",
    "        # Create vector store\n",
    "        vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)\n",
    "\n",
    "        # Create the chain object\n",
    "        chain = create_conversational_chain(vector_store)\n",
    "\n",
    "        \n",
    "        display_chat_history(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Streamlit requires raw Python (.py) files, not .ipynb.\n",
      "For more information, please see https://docs.streamlit.io\n"
     ]
    }
   ],
   "source": [
    "!streamlit run test.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
