{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [],
      "source": [
        "# llama-index openai transformers accelerate optimum InstructorEmbedding sentence_transformers pypdf chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGOAxDUvKlE",
        "outputId": "0a3e60f4-603e-49a5-dce7-852b73770392"
      },
      "outputs": [],
      "source": [
        "# !pip install -q llama-index chromadb --quiet\n",
        "# !pip install -q chromadb\n",
        "# !pip install -q sentence-transformers\n",
        "# !pip install -q pydantic==1.10.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LYEnctgbBWA"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR-OPENAI-API-KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y_E6BUZrYp-",
        "outputId": "3961379e-00c5-4505-d079-8e6ce2c76ee6"
      },
      "outputs": [],
      "source": [
        "# !curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "482wzQ6mvYxS"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.vector_stores import ChromaVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.embeddings import HuggingFaceEmbedding\n",
        "from llama_index.llms import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "import chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8pfCTvG9vY8m"
      },
      "outputs": [],
      "source": [
        "# define embedding function\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# print(embed_model(\"This is a test sentence.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MPhHSUtnvY_c"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\n",
        "    input_dir='/Users/matansharon/python/chat_with_docs/data/temp/'\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YB_KolqI3pg4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id_='a81443a5-482b-4df5-a071-e77e954a7e7e', embedding=None, metadata={'page_label': '1', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='fa91b8e43cf28f6f84cf4c2347e5869b5bc1278eefb465bf26f530ca22d33e58', text='Machine Learning Roadmap 2020(a machine-learning-flavoured-visual-iterative-living-mind-map/compass)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='6f9f1940-22ab-442f-8ecd-fb13f0a2ea73', embedding=None, metadata={'page_label': '2', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='913af5dfbda6f3ed39f42f147a624704aab66b737e036e9a9681f83c9223834a', text='The curious internet-dwelling user (maybe you)‚ÄúWhat is machine learning?‚Äù', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ea6a845b-d7dc-4d86-82a8-b62063e9306f', embedding=None, metadata={'page_label': '3', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b14894680b6079f1290ec0f08c6c486c4561ccc43e81cf49eba6d54774e9f185', text='Machine learning is turning things (data) into numbers and finding patterns in those numbers.The computer does this part. How? Math. (we‚Äôll cover a little on this later)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c6d5c124-77f8-4da7-ad2c-66609fa3e9dd', embedding=None, metadata={'page_label': '4', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ef2b0daaa6730a66f7e6b697d890fb61113b2f95c00b9823cb3e007e0d3fa455', text='Traditional programming (software 1.0) vs. Machine learning (software 2.0)(requires 1.0)(does not require 2.0)\\nAndrei Karpathy post: Software 2.0', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5310c665-80b9-44a0-9768-b731ddd150a3', embedding=None, metadata={'page_label': '5', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b765062c6fc7e809dffcf21ce2f15b9ab8adafd1e3e450322a3109ce60f6e717', text='Traditional  programming\\nMakes\\n1.Cut vegetables 2.Season chicken 3.Preheat oven 4.Cook chicken for 30-minutes 5.Add vegetablesStarts withMachine learning  algorithmFigures out1.Cut vegetables 2.Season chicken 3.Preheat oven 4.Cook chicken for 30-minutes 5.Add vegetables\\nStarts withInputsOutput', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ef67e95e-fa2a-4b14-93dc-0cf1a7ee1663', embedding=None, metadata={'page_label': '6', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='2c7ba34b8c9b3cf8502775845d4c863464b4c96be9fb6458d9249caa70c7ab94', text='Another curious (perhaps even more curious than before) internet dweller‚ÄúWhy use machine learning?‚Äù', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='fbbf4246-658a-49fa-8166-9cd056b0ad00', embedding=None, metadata={'page_label': '7', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5bc12dd4ae97e184e3f841f39621c71e490508912ad0f2acc4eee472d896349c', text='Better reason: Can you think of all the rules?(probably not)Good reason: Why not?  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='b9537fe0-3afe-4bab-8fe6-3d0d13ed1ad1', embedding=None, metadata={'page_label': '8', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e63b3da5f108f31f9bf50d187dcb60b373243954239c0fa7d95de21109d8675b', text='A wise software engineer‚Ä¶ (actually rule 1 of Google‚Äôs Machine Learning Handbook)‚ÄúIf you can build a simple rule-based system that doesn‚Äôt require machine learning, do that.‚Äù(maybe not very simple‚Ä¶)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='107047bf-0c05-4f4b-a62c-35b60b6149bc', embedding=None, metadata={'page_label': '9', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a636c8b9b55a4dfb58f3c3609a4c2201c238465084aefdf5e2f4a07ecf874e7a', text='What machine learning is good for‚Ä¢Problems with long lists of rules‚Äîwhen the traditional approach fails, machine learning may help.\\n‚Ä¢Continually changing environments‚Äîmachine learning can adapt (‚Äòlearn‚Äô) to new scenarios.\\n‚Ä¢Discovering insights within large collections of data‚Äîcan you imagine trying to go through every transaction your (large) company has ever had by hand?\\nü§ñ\\n‚úÖ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='fcf4d210-5f40-4496-840e-5747ea967a75', embedding=None, metadata={'page_label': '10', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='350ff3f02ebdbd35e54716828784110270f26bf65a8504fefa3c4da8a54bd89f', text='Source: Tesla Autonomy Day videoProblems with long lists of rules\\nContinually changing environmentsDiscovering insights  within large collections  of data', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8bb834de-5c69-4f76-9d3b-4794afdb0cdc', embedding=None, metadata={'page_label': '11', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e5b56754cb1af3cbd9b3a32ed922cf7e833a7c45bd1b9bc1d463116621e96131', text='What we‚Äôre going to cover1.\\nü§î Machine Learning Problems‚Äîwhat does a machine learning problem look like?\\n2.\\n‚ôª Machine Learning Process‚Äîonce you‚Äôve found a problem, what steps might you take to solve it? 3.\\nüõ† Machine Learning Tools‚Äîwhat should you use to build your solution? 4.\\nüßÆ Machine Learning Mathematics‚Äîwhat exactly is happening under the hood? 5.\\nüìö Machines Learning Resources‚Äîokay, this is cool, how can I learn all of this?(broadly)\\nHow:\\nüë©üî¨\\nüë©üç≥', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5f598034-5436-4b27-a5d9-31476f5684b6', embedding=None, metadata={'page_label': '12', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ba58006166a2933537669dfaa0b45f213f9fe5938b02afca5a53ac8acb627c38', text='How to approach this roadmap‚Ä¢Explore ‚Ä¢Comment ‚Ä¢Give feedback, give advice ‚Ä¢Share ‚Ä¢Follow your curiosity ‚Ä¢Explore(twice on purpose)(there‚Äôs a lot, so don‚Äôt expect to get it all)(what‚Äôs missing?)\\nüß≠\\nüó∫(actually a compass)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='102218d0-c6a0-44ab-94d3-7fea909ec4aa', embedding=None, metadata={'page_label': '13', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e361ea428b744388adb9dd9e34778e73b253c62859aa950caa452bb199c3d153', text='Okay, let‚Äôs go.Ready?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cf334cc5-9209-4e0d-b5e6-4d5478b7050b', embedding=None, metadata={'page_label': '14', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7d0c75918568e108366575affa3c8b7318531ee1d0d1cd50a25423164fa8e674', text='1. \\nü§î Machine Learning Problems', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='82b9b9d3-9041-4a3a-a392-8381664ffb95', embedding=None, metadata={'page_label': '15', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='656262e9752c77a63b6f2501a61af9a4307784fbe42a72fd3b9f9ccafb1f7087', text='1. \\nü§î Machine Learning Problems\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cd1e0171-3a61-4d6c-9159-f8dc04b5ccde', embedding=None, metadata={'page_label': '16', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='5a76091c76963859b5b97845dc873ee8418a142520bdfa03df0ab13fcd44a954', text='1. \\nü§î Machine Learning Problems\\nSupervised  Learning\\nUnsupervised LearningReinforcement Learning\\nTransfer  Learning\\n(categories of learning)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e05cd7a0-683d-46e1-9488-4bd0cd33773b', embedding=None, metadata={'page_label': '17', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='72095fcf7f5eb9e62d63adc06df730f69fda37fd0dc6303c0498d64a4dec64dc', text='1. \\nü§î Machine Learning Problems(problem domains)\\nClassiÔ¨ÅcationHeart disease?\\nRegressionClusteringIDWeightHeartrateAgeHeart Disease?076545501814234029070470367100791(dropped)\\nDimensionality reduction(most important)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2dcfb418-0e35-48dd-bd37-26e7a40e8c36', embedding=None, metadata={'page_label': '18', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1cd4d61ad059c4484209e5bb160091036e1044245152e171a802c35ad11e74f4', text='2. \\n‚ôª Machine Learning Process', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='84c55399-a504-4151-8819-9e1d96afb768', embedding=None, metadata={'page_label': '19', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='62932377e26a1108fb80ad26459c107f98ac74a6886400153a8ea24076df89a8', text='2. \\n‚ôª Machine Learning Process\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='010025e4-9e1b-4a2b-8ffa-9bedb367a06d', embedding=None, metadata={'page_label': '20', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7bc21db3b4304f9b43550ac387156c0d9c692b3406a74bae7d86cdcd8c639282', text='Source: Tesla Autonomy Day video', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c0147419-7fdd-437d-b258-eedd3e5251d0', embedding=None, metadata={'page_label': '21', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='eee18e24490a594e1a3398f263a7fbf666d57b6e050ef23927b6bbb70b13716e', text='Source: Tesla Autonomy Day video\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='54d5d16e-6eca-41f3-ae4e-9134cedca0ff', embedding=None, metadata={'page_label': '22', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='129e54c07edfbc3a315bd9952b29b2c35f803a4e50c03e045c5a5d13511e8455', text='2. \\n‚ôª Machine Learning Process\\ndbourke.link/airbnbplaylist', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='629625f3-3744-47aa-a1e4-c6e91f27e9fa', embedding=None, metadata={'page_label': '23', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3234b75ebc684ab29d72efa52174c3964ec34f2f783f6f4822362999ad2714b3', text='3. \\nüõ† Machine Learning Tools', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='8adbdd05-9f73-4d8c-9442-970559420bbe', embedding=None, metadata={'page_label': '24', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='b9c16b2052cd71ebe6252e812a7a4b3c53fd4b09499d516cdf82d433bf7e03ca', text='3. \\nüõ† Machine Learning Tools\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='697203e5-b0b7-4d7e-9c32-b1b2363bd4fe', embedding=None, metadata={'page_label': '25', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7c744a28f53214e088f561293af95ad661da785363dd156ed4f24544a6b6c787', text='4. \\nüßÆ Machine Learning Mathematics', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='abc59353-32cf-4db0-a353-08ec423f9a60', embedding=None, metadata={'page_label': '26', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='144ded2015e0cd854a269c0c244c7f53a134887f6a48d405388626bd29c23949', text='4. \\nüßÆ Machine Learning Mathematics\\nLinear AlgebraMatrix ManipulationMultivariate CalculusThe Chain RuleProbability + DistributionsOptimization(some of the main ones)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='a4b68bf6-d2ac-46ea-9450-acd254a5cb0a', embedding=None, metadata={'page_label': '27', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='ddf3256fe5b68a1efbd06461d32adf6905d701709bcf773b754388c819681c60', text='5. \\nüìö Machine Learning Resources', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='80893cb0-04e3-45f3-87ab-d254ae7e38d3', embedding=None, metadata={'page_label': '28', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1a83099dfa6db20ded8ca668d4b0ee60c066a470d0f0495947d83c3153e89e40', text='5. \\nüìö Machine Learning Resources(where to start learning)\\ndbourke.link/mlcourse\\nPart 1\\nPart 2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='f62b0f4f-20b0-46b2-bb1a-649feffc814f', embedding=None, metadata={'page_label': '29', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='308da8349d50de1b236ddab6cab2bf915a009a379fc219878d11e769ca97d7ff', text='5. \\nüìö Machine Learning Resources(example curriculums)\\ndbourke.link/aimastersdegree\\nhttps://jasonbenn.com/post/how-i-learned-to-code ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='4f8e13e2-d30a-4e9d-a13e-74ed349dea44', embedding=None, metadata={'page_label': '30', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='4b3de9f35169e59c6563bc6979671f446caa1430ff4af10e2c475db859394b6d', text='5. \\nüìö Machine Learning Resources(some useful places to visit)\\nsotabench\\nPapers with Code\\nMade with ML', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='2ce9665c-2a8a-4159-9263-891c9c5852a4', embedding=None, metadata={'page_label': '31', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='531cb886b40254b69faa7db91f834a9ad5e035e894d708975337e815d04cc22d', text='Summary, plus next stepsEnd', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='a514c6ff-f040-4f49-99e1-b369fbfa7848', embedding=None, metadata={'page_label': '32', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='594e63077ffbf998755bdf29a91e98ca43f93e99b3921fc15b7a2314c34b5972', text='What we‚Äôre going to covered1.\\nü§î Machine Learning Problems‚Äîwhat does a machine learning problem look like?\\n2.\\n‚ôª Machine Learning Process‚Äîonce you‚Äôve found a problem, what steps might you take to solve it? 3.\\nüõ† Machine Learning Tools‚Äîwhat should you use to build your solution? 4.\\nüßÆ Machine Learning Mathematics‚Äîwhat exactly is happening under the hood? 5.\\nüìö Machines Learning Resources‚Äîokay, this is cool, how can I learn all of this?(broadly)\\nHow:\\nüë©üî¨\\nüë©üç≥', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d7344365-aeb0-41ea-b6aa-5abbdbda9dd3', embedding=None, metadata={'page_label': '33', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='01615d471915411a57e0d465cdc80138c3a0894ff713e8829f617893ba3e579a', text='What‚Äôs missing?‚Ä¢Instance vs. model-based learning ‚Ä¢Machine learning pipelines (still emerging on best practices) ‚Ä¢More speciÔ¨Åc topics (such as computer vision, NLP , RL‚Ä¶) ‚Ä¢Probably much more (leave a comment)\\nüßê', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c54adfb1-cacd-4d39-82a7-34dae32680dc', embedding=None, metadata={'page_label': '34', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0c1c3a04ca81ad0fa365bd76ed1df803d407d8a663f11822bc744e068f9c2c0d', text='Sources (thank you‚Äôs)‚Ä¢Daniel Formoso‚Äôs machine learning mind maps\\n‚Ä¢Hands-on Machine Learning Book (2nd edition)\\n‚Ä¢100-page Machine Learning Book ‚Ä¢Countless blog posts (check the mind map for links)\\nüëè', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='71b2c109-b9c9-4de4-beff-1ff4152e583b', embedding=None, metadata={'page_label': '35', 'file_name': '2020-ml-roadmap-keynote.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='0bdea5f16966bdb0bbb96795ed49b6dc6d60f4aad198b9aed21316afae93f4c8', text='Keep learning Keep creating(machine)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        }
      ],
      "source": [
        "print(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jlgXGp47cu"
      },
      "source": [
        "# CHROMA-DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP1CgwWR4H5E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FLmWj6-dwVyN"
      },
      "outputs": [],
      "source": [
        "# create client and a new collection\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "chroma_collection = chroma_client.create_collection(\"test1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG5Hlw2V4Q_M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zBzlbcwLq_"
      },
      "source": [
        "### Set up ChromaVectorStore and load in data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g1KwBHHuwKyD"
      },
      "outputs": [],
      "source": [
        "# set up ChromaVectorStore and load in data\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TPDtjS5P4fn2"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XnwdnuZn4frc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******\n",
            "Could not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\n",
            "Original error:\n",
            "No API key found for OpenAI.\n",
            "Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\n",
            "API keys can be found or created at https://platform.openai.com/account/api-keys\n",
            "\n",
            "******\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/matansharon/Library/Caches/llama_index/models/llama-2-13b-chat.Q4_0.gguf (version GGUF V2 (latest))\n",
            "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  5120, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
            "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
            "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
            "llama_model_loader: - kv   0:                       general.architecture str     \n",
            "llama_model_loader: - kv   1:                               general.name str     \n",
            "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
            "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
            "llama_model_loader: - kv  10:                          general.file_type u32     \n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
            "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q4_0:  281 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_print_meta: format           = GGUF V2 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = mostly Q4_0\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
            "llm_load_print_meta: general.name   = LLaMA v2\n",
            "llm_load_print_meta: BOS token = 1 '<s>'\n",
            "llm_load_print_meta: EOS token = 2 '</s>'\n",
            "llm_load_print_meta: UNK token = 0 '<unk>'\n",
            "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.12 MB\n",
            "llm_load_tensors: mem required  = 7024.01 MB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 3900\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_new_context_with_model: kv self size  = 3046.88 MB\n",
            "llama_new_context_with_model: compute buffer total size = 348.18 MB\n",
            "llama_new_context_with_model: max tensor size =   128.17 MB\n",
            "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  7024.61 MB, ( 7025.23 / 10922.67)\n",
            "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3048.88 MB, (10074.11 / 10922.67)\n",
            "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   342.31 MB, (10416.42 / 10922.67)\n",
            "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Psv-DFtX4ful"
      },
      "outputs": [],
      "source": [
        "\n",
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "M9KHTQG8wK3_",
        "outputId": "ed5ba2d9-fde5-4772-97fa-a29f0987201a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time = 20662.52 ms\n",
            "llama_print_timings:      sample time =   125.41 ms /    49 runs   (    2.56 ms per token,   390.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time = 16221.14 ms /    49 runs   (  331.04 ms per token,     3.02 tokens per second)\n",
            "llama_print_timings:       total time = 16724.18 ms\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "  Based on the provided context information, the main keynote of machine learning (ML) is to build a simple rule-based system that does not require ML, as stated in the quote from Google's Machine Learning Handbook."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"what is the main keynote of ml?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFasbpZJ0TUb"
      },
      "source": [
        "### How to Persist: Saving to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5i5lxQrvZCu"
      },
      "outputs": [],
      "source": [
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "\n",
        "chroma_collection = db.get_or_create_collection(\"DB_collection\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model,\n",
        "                                               chunk_size=800,\n",
        "                                               chunk_overlap=20)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V69BQgST6aId"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9Z8BmH1BaM"
      },
      "source": [
        "### Load from Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytlj_EPVvZFm"
      },
      "outputs": [],
      "source": [
        "# load from disk\n",
        "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "chroma_collection = db2.get_or_create_collection(\"DB_collection\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store,\n",
        "    service_context=service_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "nJ1bh3zh1OD7",
        "outputId": "52d8adfa-0b78-4f6b-b3b8-c97f3ee2aad5"
      },
      "outputs": [],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What are some of the main contributions of this new Orca model?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-qGk3n-7Suh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWGp_dP6mPY"
      },
      "source": [
        "# PINECONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOr6p10m1OJ0"
      },
      "outputs": [],
      "source": [
        "!pip install -q pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_nzoUZh1OM8"
      },
      "outputs": [],
      "source": [
        "import pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEzw43BoC5P7"
      },
      "outputs": [],
      "source": [
        "os.environ['PINECONE_API_KEY'] = \"PINECONE_API_KEY\"\n",
        "os.environ['PINECONE_ENVIRONMENT'] = 'gcp-starter'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTokcpnr1OP0"
      },
      "outputs": [],
      "source": [
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ['PINECONE_API_KEY'],\n",
        "    environment=os.environ['PINECONE_ENVIRONMENT']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwAPbSv8Dy6I"
      },
      "outputs": [],
      "source": [
        "# create the index if it does not exist already\n",
        "index_name = 'llamaindex'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=768,\n",
        "        metric='cosine'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmA9O7nqENlK",
        "outputId": "e8735c6e-2c52-44e1-c786-6b6eeecdf171"
      },
      "outputs": [],
      "source": [
        "pinecone_index = pinecone.Index(\"llamaindex\")\n",
        "pinecone.describe_index(\"llamaindex\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kltmj58fENod"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores import PineconeVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL9KY3P8ENrl"
      },
      "outputs": [],
      "source": [
        "# set add_sparse_vector=True to compute sparse vectors during upsert\n",
        "from llama_index.storage.storage_context import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwT2d7oFENu8"
      },
      "outputs": [],
      "source": [
        "vector_store = PineconeVectorStore(\n",
        "    pinecone_index=pinecone_index,\n",
        "    # add_sparse_vector=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTzwIpi5ENy1"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b58206b26c764c02a5dcc77a022b7b38",
            "6afddafd20254a0aa4895e311000f104",
            "f1e98261f3ce46139ae4b037bd0ea918",
            "f21284f9f56040f3abc9585bdd99816c",
            "a0a9ec8e01254b63a7659c4476fbc5c7",
            "e3c2934caa814a4a97b84f4d28a15686",
            "7427c25da71547f0b03dbeba6b01378e",
            "d93420720cb945e6a5094781ec5c8ba8",
            "60b9f3faaa52444498b3f5e7d5ba058e",
            "8de1e4e251d240e281f1921ab7913fc9",
            "d401f7ed4b404fecb9239fa5b2aeb675"
          ]
        },
        "id": "WKW4s4YoEN1V",
        "outputId": "06674e1e-a7c9-41f5-fc28-822277a02dd7"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yQ2waFYsFOfu",
        "outputId": "c589b140-6b7a-4b15-c0f1-1c28e428d0de"
      },
      "outputs": [],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is Big-Bench Hard test?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Y1fjC4FOjD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_17Kx7aFOmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXSbsstFOpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60b9f3faaa52444498b3f5e7d5ba058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6afddafd20254a0aa4895e311000f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c2934caa814a4a97b84f4d28a15686",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7427c25da71547f0b03dbeba6b01378e",
            "value": "Upserted vectors: 100%"
          }
        },
        "7427c25da71547f0b03dbeba6b01378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de1e4e251d240e281f1921ab7913fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a9ec8e01254b63a7659c4476fbc5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58206b26c764c02a5dcc77a022b7b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6afddafd20254a0aa4895e311000f104",
              "IPY_MODEL_f1e98261f3ce46139ae4b037bd0ea918",
              "IPY_MODEL_f21284f9f56040f3abc9585bdd99816c"
            ],
            "layout": "IPY_MODEL_a0a9ec8e01254b63a7659c4476fbc5c7"
          }
        },
        "d401f7ed4b404fecb9239fa5b2aeb675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93420720cb945e6a5094781ec5c8ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c2934caa814a4a97b84f4d28a15686": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e98261f3ce46139ae4b037bd0ea918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93420720cb945e6a5094781ec5c8ba8",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b9f3faaa52444498b3f5e7d5ba058e",
            "value": 55
          }
        },
        "f21284f9f56040f3abc9585bdd99816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de1e4e251d240e281f1921ab7913fc9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d401f7ed4b404fecb9239fa5b2aeb675",
            "value": " 55/55 [02:25&lt;00:00, 37.46it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
