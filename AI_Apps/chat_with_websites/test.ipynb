{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever,create_retrieval_chain\n",
    "from langchain.chains.combine_documents import  create_stuff_documents_chain\n",
    "load_dotenv()\n",
    "\n",
    "def get_urls():\n",
    "    return[\"https://en.wikipedia.org/wiki/2024_United_States_presidential_election,\"\n",
    "           \n",
    "        \n",
    "    ]\n",
    "def get_vectorstore_from_url(url):\n",
    "    url=\"https://en.wikipedia.org/wiki/2024_United_States_presidential_election\"\n",
    "    loader=WebBaseLoader(url)\n",
    "    document=loader.load()\n",
    "    text_splitter=RecursiveCharacterTextSplitter()\n",
    "    document_chunks=text_splitter.split_documents(document)\n",
    "    vector_store=Chroma.from_documents(document_chunks,OpenAIEmbeddings()) \n",
    "    return vector_store\n",
    "\n",
    "def context_retriever_chain(vector_store):\n",
    "    llm=ChatOpenAI()\n",
    "    retriever=vector_store.as_retriever()\n",
    "    prompt=ChatPromptTemplate.from_messages(\n",
    "        [MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "         (\"user\", \"{input}\"), \n",
    "         \n",
    "         ])\n",
    "    retriever_chain=create_history_aware_retriever(llm,retriever,prompt)\n",
    "    return retriever_chain\n",
    "\n",
    "\n",
    "def get_conversion_rag_chain(retriever_chain):\n",
    "    llm = ChatOpenAI()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system', \"answer the following questions based on the below context:\\n\\n{context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    # Correctly call create_retrieval_chain with the retriever_chain and stuff_documents_chain\n",
    "    combined_retrieval_chain = create_retrieval_chain(retriever_chain, stuff_documents_chain)\n",
    "    return combined_retrieval_chain\n",
    "\n",
    "def get_response(user_input,conversation_rag_chain):\n",
    "    conversation_rag_chain=conversation_rag_chain\n",
    "    response = conversation_rag_chain.invoke({\n",
    "                \"chat_history\": [],\n",
    "                \"input\": user_input\n",
    "            })\n",
    "    return response['answer']\n",
    "    # context=\"\"\n",
    "    # for res in response:\n",
    "    #     context+=res.page_content\n",
    "    # llm=ChatOpenAI()\n",
    "    # return llm.invoke(f\"answer the following questions based on the below context:\\n\\n{context}\")\n",
    "\n",
    "\n",
    "def initialize_session_state():\n",
    "    vector_store, retriever_chain, conversion_rag_chain, urls = run()\n",
    "    st.session_state[\"init\"] = True\n",
    "    st.session_state[\"vector_store\"] = vector_store\n",
    "    st.session_state[\"retriever_chain\"] = retriever_chain\n",
    "    st.session_state[\"conversion_rag_chain\"] = conversion_rag_chain\n",
    "    st.session_state[\"urls\"] = urls\n",
    "    st.session_state['chat_history'] = [AIMessage(\"Hello! I am a bot. Ask me anything!\")]\n",
    "\n",
    "def run():\n",
    "    urls=get_urls()\n",
    "    vector_store=get_vectorstore_from_url(urls)\n",
    "    retriever_chain=context_retriever_chain(vector_store=vector_store)\n",
    "    conversation_rag_chain = get_conversion_rag_chain(retriever_chain=retriever_chain)\n",
    "    \n",
    "    return conversation_rag_chain,vector_store,retriever_chain,urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_rag_chain,vector_store,retriever_chain,urls=run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=get_response(\"What is the 2024 United States presidential election?\",conversation_rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "_urls=[\"https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfmaude/search.cfm\",\n",
    "\"https://en.wikipedia.org/wiki/2024_United_States_presidential_election\",\n",
    "\"https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm\",\n",
    "\"https://pubmed.ncbi.nlm.nih.gov/\",\n",
    "\"https://ec.europa.eu/tools/eu\"]\n",
    "\n",
    "def get_vectorstore_from_url(urls):\n",
    "    # get the text in document form\n",
    "    all_documents = []\n",
    "    for url in urls:\n",
    "        loader = WebBaseLoader(url)\n",
    "        document = loader.load()\n",
    "    \n",
    "    # split the document into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter()\n",
    "        document_chunks = text_splitter.split_documents(document)\n",
    "        all_documents.extend(document_chunks)\n",
    "    \n",
    "    # create a vectorstore from the chunks\n",
    "    vector_store = Chroma.from_documents(documents=all_documents, embedding=OpenAIEmbeddings(),persist_directory=\"website_db\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=get_vectorstore_from_url(_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2=Chroma(persist_directory=\"website_db\",embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=db2.similarity_search(\"What is the 2024 United States presidential election?\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this project is incredible let me show you what is essentially a completely open-source version of perplexity and if you're not familiar with perplexity this is it it's basically an answer engine and a lot of people are using it instead of Google Search now you enter your query and it uses artificial intelligence to put together a page to answer your question directly let me show you so I'm going to ask how do I make ramen and so we got pictures of ramen over on the right side we have the answer right here step by step it also has the sources that it pulled this information from so it basically is Google search but instead of having to click through a bunch of links it gives you the answer directly and it's super useful but what if I wanted to do this completely open source and even run it using open source models well that's what this is I'm on Local Host 3000 and this is called answer engine so let me ask the same question how do I make wrong all right we got pictures we have videos right there and here we go I'm using mixl on grock and it gave me step-by-step instructions for how to make ramen gave me sources right there I can click on any of these videos and it'll play the video I can click on that video so all the videos are played in the same screen I can click the images here's another one here's another one and it is super fast super easy to use and I'm going to show you how to do it so let's go all right so this project is by developers digest at Devore digest on X today I'm open sourcing my next JS llm answer engine so it is supposed to be essentially an open- Source version of perplexity it uses versel it uses Gro for the inference very fast inference I must say mistal AI Labs Lang chain open Ai embeddings and brave and serper API and this is the GitHub URL and it's still a relatively new project the entire thing was only created a few days ago it has 300 stars but hopefully after this video it gains a lot of momentum because this is an awesome project all right so to install it we're going to open up VSS code you're going to click up in the top right to open a new terminal we're going to CD to your desktop or wherever you want to clone the repository switching back to the GitHub repo we're going to click this green code button and then we're going to click copy URL to clipboard switch back to vs code and we're going to type git clone and then we're going to paste in the GitHub repository hit enter okay now that that's done we're going to CD into llm answer engine llm D answer- engine hit enter now according to the instructions you can either use npm or bun and I've been using bun a little bit lately so let's use that so I'm going to type bun install and then it's going to install all the requirements very fast okay now that we're done done with that we're going to click file open folder go to the desktop and then we're going to open up our llm answer engine in vs code now we have this mv. example so you're going to right click on that and we're going to click rename and we're going to rename it to just. MV hit enter open it up and here we're going to enter our open AI API key for the embeddings we're going to use grock for mixl brave for the search and serper API for search also so let's grab the openai API key first so if you don't already have a developer account with open ai go ahead and sign up I'm going to click create new key I'm going to name it peryt for perplexity hit enter I'm going to grab this API key and I am going to revoke this API key before publishing this video all right so we paste it in right there and then we need the grock API key so we're going to go to console. gro.com playground we're going to click the API Keys button right there I'm going to click create new key we're going to call it per YT I'm going to hit enter copy the key switch back to VSS code I'm going to paste it in right there next let's grab the brave key and one by one we're going to grab them all so once again sign up for brave it is free I believe you have to put your credit card in but they're not going to charge you anything so I already created a key right there I'm just going to go ahead and copy it but if you haven't you add API key right there so I'm going to click and enter it right there and then for serper we need that as well so let's go grab that so I signed in into serper click the API key and I'm going to copy it right there paste it in hit save now we have everything we need and that's really it so now that we have all the API Keys set up we're going to click the terminal button right there we're still in llm answer engine and we just do Bun Run Dev hit enter all right there now it's up and running ready in 11 seconds so hold down your command key and then click on local host or you can just simply copy paste it and we can see it's compiling so the first time it runs it takes a little while and there it is llm answer engine so let's give it a try how do I make ramen hit enter and there we go it all works uh amazing I absolutely love this so if you have the server running in the background you can have essentially perplexity for free anytime you want running locally all right so let's say you want to run the models completely locally so I downloaded and installed olama and if you don't know how to do that just go to ol. a it's super simple I'm going to open up a new terminal I'm going to make sure we have Ama running okay so we do I'm going to list I have no models downloaded so let's download let's download mistol because it's smaller it'll run quickly and it'll be easier to run on my machine so AMA pull mistol and it's going to download mistol it's only 4 GB so it should only take a couple minutes now let me tell you what we're going to do while it's downloading right here we're just going to replace the base URL and that's really it so we replace the base URL with our o llama served endpoint and then then for the API key we're simply going to put in olama but I'll show you that in a moment now the only other thing that hits a third-party API that actually costs money is the open AI embeddings now I don't think there's a way to add for example no mix embeddings that can run locally and is really fast but if this project gets enough momentum hopefully we can replace the embeddings with something local and then really the only thing we're doing after that is searching and that obviously can't be local and so that be the only piece that actually hits the web but that is a requirement because we're actually doing a Google search to find some of this information all right so it's done downloading success and now let's make sure we are serving it so olama serve hit enter okay so I tried to do AMA serve but I think since I already have olama running we don't need to do that again so we're going to replace this base URL right there and I believe we're going to replace it all the way through V1 so let's go ahead and replace that and then for the API key we're going to use olama then we're saving it so that should work let's switch back to bun okay let's restart the server just in case I don't think you have to with next but let's do it anyways okay all done we have the answer engine let's refresh the page okay how do I make ramen and let's see if it worked all right so I could not get this to work with olama I suspect I'm pretty close but I'm going to tell you what I've done so far and then maybe you could either fix it or maybe there is something Act wrong but either way let me show you what I've done so for the base URL I'm using Local Host colon 11434 slv1 and that is the URL that olama serves when you start it up API key right there olama now if I switch over to the AMA tab which I'm already in you could see when I'm hitting the endpoint it's actually receiving it so you could see it might be processing my video actually might be running a little bit slow right now but it's not quitting so I'm going to quit out of there and what I did is _ host equals 000000 AMA serve and I did this because there seems to be a little issue with olama recently and you actually have to specify the Local Host but let's give it a try so then I just hit serve and it loads then from here I search for all the times that were referencing the model name so I just did a code wide search for model and before it had mixol in here so I just replaced it with mistol so let's go back Bun Run Dev and let's see if we can get it running one more time all right so I said how do I make ramen and here we go you can see a bunch of stuff just got output so it definitely got the request but nothing's happening in the interface I don't see any errors either so very odd I'm not sure why it's not working maybe it's that mistol isn't actually returning anything useful it could be that and I need to try mixol but either way it seems to be getting the request it seems to be responding responding correctly so it could be the fact that it's responding with something that this project doesn't understand because it's not actually using the mixt tral model but either way awesome project try it out let me know if you get a Lama working and if you do drop a comment and tell me how you did it if you liked this video please consider giving a like And subscribe and I'll see you in the next one \n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi \n",
    "\n",
    "  \n",
    "# assigning srt variable with the list \n",
    "# of dictionaries obtained by the get_transcript() function\n",
    "url='https://www.youtube.com/watch?v=GanTUWLUUWQ'\n",
    "id=url.split('=')[1]\n",
    "srt = YouTubeTranscriptApi.get_transcript(id)\n",
    "\n",
    "  \n",
    "# prints the result\n",
    "text=''\n",
    "for i in srt:\n",
    "    text+=i['text']+' '\n",
    "print((text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import (\n",
    "    YoutubeAudioLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import OpenAIWhisperParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader(YoutubeAudioLoader(['https://www.youtube.com/watch?v=GanTUWLUUWQ'], '.'), OpenAIWhisperParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=GanTUWLUUWQ\n",
      "[youtube] GanTUWLUUWQ: Downloading webpage\n",
      "[youtube] GanTUWLUUWQ: Downloading ios player API JSON\n",
      "[youtube] GanTUWLUUWQ: Downloading android player API JSON\n",
      "[youtube] GanTUWLUUWQ: Downloading m3u8 information\n",
      "[info] GanTUWLUUWQ: Downloading 1 format(s): 140\n",
      "[download] Destination: ./Answer Engine Tutorial： The Open-Source Perplexity Search Replacement.m4a\n",
      "[download] 100% of    8.63MiB in 00:00:01 at 6.78MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: GanTUWLUUWQ: writing DASH m4a. Only some players support this container. Install ffmpeg to fix this automatically\n",
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3512\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[0;34m(self, info_dict)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3512\u001b[0m     replace_info_dict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles_to_move\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3694\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[0;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[1;32m   3693\u001b[0m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__files_to_move\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m files_to_move \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m-> 3694\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_pps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_process\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_pps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__postprocessors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3695\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[38;5;28mself\u001b[39m), info)\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3676\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[0;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[1;32m   3675\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pp \u001b[38;5;129;01min\u001b[39;00m (additional_pps \u001b[38;5;129;01mor\u001b[39;00m []) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pps[key]:\n\u001b[0;32m-> 3676\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3654\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[0;34m(self, pp, infodict)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3654\u001b[0m     files_to_delete, infodict \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfodict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# Must be True and not 'only_download'\u001b[39;00m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/postprocessor/common.py:23\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[0;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_progress({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted\u001b[39m\u001b[38;5;124m'\u001b[39m}, info_copy)\n\u001b[0;32m---> 23\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/postprocessor/common.py:128\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed[format_type]:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/postprocessor/ffmpeg.py:493\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[0;34m(self, information)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], information\n\u001b[0;32m--> 493\u001b[0m filecodec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_audio_codec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filecodec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/postprocessor/ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe_available \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PostProcessingError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/langchain_community/document_loaders/generic.py:115\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    113\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_loader\u001b[38;5;241m.\u001b[39myield_blobs():\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_parser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/langchain_community/document_loaders/blob_loaders/youtube_audio.py:45\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Download file\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m yt_dlp\u001b[38;5;241m.\u001b[39mYoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[0;32m---> 45\u001b[0m         \u001b[43mydl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Yield the written blobs\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loader \u001b[38;5;241m=\u001b[39m FileSystemBlobLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.m4a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3558\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[0;34m(self, url_list)\u001b[0m\n\u001b[1;32m   3555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[1;32m   3557\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[0;32m-> 3558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__download_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_info\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_generic_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforce_generic_extractor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3533\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   3531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3532\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3533\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3534\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnavailableVideoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3535\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_error(e)\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1583\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[0;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached()\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__extract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_info_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     extractors_restricted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowed_extractors\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1594\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[38;5;241m.\u001b[39mIndexError, PagedList\u001b[38;5;241m.\u001b[39mIndexError):\n\u001b[1;32m   1596\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1750\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[0;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_video(ie_result)\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_ie_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ie_result\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1809\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[0;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[0;32m-> 1809\u001b[0m     ie_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[1;32m   1811\u001b[0m     additional_urls \u001b[38;5;241m=\u001b[39m (ie_result \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditional_urls\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:2968\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[0;34m(self, info_dict, download)\u001b[0m\n\u001b[1;32m   2966\u001b[0m downloaded_formats\u001b[38;5;241m.\u001b[39mappend(new_info)\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[1;32m   2970\u001b[0m     max_downloads_reached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:3514\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[0;34m(self, info_dict)\u001b[0m\n\u001b[1;32m   3512\u001b[0m     replace_info_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3514\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPostprocessing: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   3516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1061\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[0;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrouble\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_err\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mERROR:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStyles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mERROR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmessage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/chat_with_doc/.venv/lib/python3.10/site-packages/yt_dlp/YoutubeDL.py:1000\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[0;34m(self, message, tb, is_error)\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    999\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_retcode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
