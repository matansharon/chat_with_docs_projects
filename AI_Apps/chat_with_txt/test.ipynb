{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is Pixegami tutorial\n",
    "### from this video :https://www.youtube.com/watch?v=tcqEUSNCn8I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splited_docs 101\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import TextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datetime import datetime\n",
    "import json\n",
    "import PyPDF2\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DIRECTORY_PATH='/Users/matansharon/python/chat_with_docs/AI_Apps/chat_with_txt/data'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_documents_names():\n",
    "    documents_names = os.listdir(DIRECTORY_PATH)\n",
    "    return documents_names\n",
    "def load_all_docs_in_data_folder(documents_names):\n",
    "    data_documents= []\n",
    "    for doc in documents_names:\n",
    "        path=os.path.join(DIRECTORY_PATH+'/',doc)\n",
    "        Document=PyPDF2.PdfReader(path)\n",
    "        text = ''\n",
    "        for page in Document.pages:\n",
    "            text += page.extract_text()\n",
    "        data_documents.append(text)\n",
    "        \n",
    "    return data_documents\n",
    "    \n",
    "    \n",
    "\n",
    "def split_text(text:str):\n",
    "    \n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks=text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def create_new_db(chunks):\n",
    "    \n",
    "    path='chroma_db'\n",
    "    if chunks:\n",
    "        print('here')\n",
    "        db=Chroma.from_texts(texts=chunks,embedding=OpenAIEmbeddings(model='text-embedding-3-small'),persist_directory=path)\n",
    "        return db\n",
    "    if not os.path.exists(path):\n",
    "        \n",
    "        db=Chroma.from_texts(texts=[''],embedding=OpenAIEmbeddings(model='text-embedding-3-small'),persist_directory=path)\n",
    "        return db\n",
    "    return load_db()\n",
    "\n",
    "def load_db():\n",
    "    db = Chroma(persist_directory=\"chroma_db\",embedding_function=OpenAIEmbeddings(model='text-embedding-3-small'))\n",
    "    return db\n",
    "\n",
    "def get_results_with_scores(query,db):\n",
    "    bar=0.5\n",
    "    res=db.similarity_search_with_relevance_scores(query,k=3)\n",
    "    \n",
    "    return res\n",
    "def get_prompt_template(results,query):\n",
    "    template=\"\"\"\n",
    "    answer the question base only on the following context:\n",
    "    {context}\n",
    "    answer the question base on the above context: {query}\n",
    "    \n",
    "    \"\"\"\n",
    "    context_texts = []\n",
    "    for i in range(len(results)):\n",
    "        context_texts.append(results[i][0].page_content)\n",
    "    temp = \"\\n\\n---\\n\\n\".join(context_texts)\n",
    "    prompt_tamplate=ChatPromptTemplate.from_template(template)\n",
    "    res=prompt_tamplate.format(context=temp,query=query)\n",
    "    return res\n",
    "\n",
    "def get_response(query,db,model):\n",
    "    results=get_results_with_scores(query,db)\n",
    "    prompt_template=get_prompt_template(results,query)\n",
    "    response=model.invoke(prompt_template)\n",
    "    return response.content\n",
    "\n",
    "def main_app():\n",
    "\n",
    "    documents_names=get_documents_names()\n",
    "    docs=load_all_docs_in_data_folder(documents_names=documents_names)\n",
    "    splited_docs=[]\n",
    "    for doc in docs:\n",
    "        chunks=split_text(doc)\n",
    "        for chunk in chunks:\n",
    "            splited_docs.append(chunk)\n",
    "            \n",
    "    print('splited_docs',len(splited_docs))\n",
    "    db=create_new_db(splited_docs)\n",
    "    return db\n",
    "db=main_app()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x294f0b610>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x294fa40d0>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(chunks)\n",
    "\n",
    "# model=ChatOpenAI()\n",
    "# query='what is qlora?'\n",
    "\n",
    "# response=get_response(query,db,model)\n",
    "# print(response)\n",
    "# db=create_new_db('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import chromadb\n",
    "from PyPDF2 import PdfReader\n",
    "path='/Users/matansharon/python/chat_with_docs/data/pdf/qlora.pdf'\n",
    "doc=PdfReader(path)\n",
    "#get the name of the document\n",
    "doc_name=path.split('/')[-1]\n",
    "\n",
    "text=''\n",
    "for page in doc.pages:\n",
    "    text+=page.extract_text()\n",
    "\n",
    "\n",
    "\n",
    "chunks=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100,length_function=len,add_start_index=True).split_text(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_response('who is the authors of the paper \"Attention Is All You Need\"',db,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat=ChatOpenAI(model='gpt-4-turbo-preview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat.invoke(f'base on this: {content} what is qlora?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
